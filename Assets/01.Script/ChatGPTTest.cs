using System;
using System.Collections;
using System.Collections.Generic;
using System.IO;
using OpenAI;
using OpenAI.Audio;
using OpenAI.Chat;
using OpenAI.Models;
using TMPro;
using UnityEngine;
using UnityEngine.Networking;
using UnityEngine.UI;
using Newtonsoft.Json;

public class ChatGPTTest : MonoBehaviour
{
    public TextMeshProUGUI ResultTextUI;
    public TMP_InputField PromptField;
    public Button SendButton;
    public RawImage image;
    public AudioSource MyAudioSource;
    
    private const string OPENAI_API_KEY = 
        "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";

    private string _sendingMessage;
    private OpenAIClient _openAIClient;

    public ComfyUIClient Client;
    // ëŒ€í™” ê¸°ë¡ì„ Message íƒ€ì…ìœ¼ë¡œ ì €ì¥
    private List<Message> _conversationHistory = new List<Message>();

    private string _positivePrompt = "";
    
    private async void Start()
    {
        // API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” : 1. ChatGPT ì ‘ì†
        _openAIClient = new OpenAIClient(OPENAI_API_KEY);

        CreateImage();
        // CHAT-F
        // C  : Context         : ë¬¸ë§¥, ìƒí™©ì„ ë§ì´ ì•Œë ¤ì¤˜ë¼
        // H  : Hint            : ì˜ˆì‹œ ë‹µë³€ì„ ë§ì´ ì¤˜ë¼
        // A  : As A role       : ì—­í• ì„ ì œê³µí•´ë¼
        // T  : Target          : ë‹µë³€ì˜ íƒ€ê²Ÿì„ ì•Œë ¤ì¤˜ë¼
        // F  : Format          : ë‹µë³€ í˜•íƒœë¥¼ ì§€ì •í•´ë¼

        string systemMessage = "ì—­í• : ë„ˆëŠ” ì´ì œë¶€í„° ê²Œì„ NPCë‹¤. ìì‹ ì„ ì‹¤ì œ ê²Œì„ ì† ê³ ì–‘ì´ ì¸ê°„ì´ë¼ê³  ìƒê°í•œë‹¤. ";
        systemMessage += "ëª©ì : ì‹¤ì œ ì‚¬ëŒì²˜ëŸ¼ ëŒ€í™”í•˜ëŠ” ê²Œì„ NPC ëª¨ë“œ ";
        systemMessage += "í‘œí˜„: ë§ ëë§ˆë‹¤ 'ëƒ¥~'ì„ ë¶™ì¸ë‹¤. í•­ìƒ 100ê¸€ì ì´ë‚´ë¡œ ë‹µë³€í•œë‹¤. ";
        systemMessage += "ì¤‘ìš”: ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•œë‹¤: ";
        systemMessage += "[json ê·œì¹™]";
        systemMessage += "{ \"Reply_message\": \"ëŒ€í™” ë‚´ìš© ëƒ¥~\", \"Appearance\": \"ì™¸ëª¨ ì„¤ëª…\", \"Emotion\": \"ê°ì • ìƒíƒœ\", \"StoryImageDescription\": \"ì´ë¯¸ì§€ ìƒì„±ìš© ì „ì²´ ì¥ë©´ ì„¤ëª…\" } ";
        systemMessage += "ì˜ˆì‹œ: { \"Reply_message\": \"ì•ˆë…•í•˜ì„¸ìš” ëƒ¥~\", \"Appearance\": \"cute cat girl with pink hair\", \"Emotion\": \"happy\", \"StoryImageDescription\": \"cute anime cat girl with pink hair, happy expression, standing in a sunny garden\" }";
        
        _conversationHistory.Add(new Message(Role.System, systemMessage));

        // 6. ë‹µë³€ ì¶œë ¥ 
        // Debug.Log($"[{choice.Index}] {choice.Message.Role}: {choice.Message} | Finish Reason: {choice.FinishReason}");
    }
    public async void OnClickSendButton()
    {
        if (string.IsNullOrEmpty(PromptField.text)) return;
        if (_openAIClient == null) return;
        SendMessage(PromptField.text);
    }

    public void OnClickCreateImage()
    {
        CreateImage();
    }
    public void CreateImage()
    {
        StartCoroutine(Client.GenerateImageAndWait(_positivePrompt, (imagePath) =>
        {
            if (!string.IsNullOrEmpty(imagePath))
            {
                Debug.Log("Generated image path: " + imagePath);
                StartCoroutine(LoadAndShowImageAlternative(imagePath));
            }
            else
            {
                Debug.LogError("Failed to get image path");
            }
        }));
    }
    public async void SendMessage(string message)
    {
        PromptField.text = string.Empty;
        
        // ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        var userMessage = new Message(Role.User, message);
        _conversationHistory.Add(userMessage);
        
        // 2. ì „ì²´ ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        var messages = new List<Message>(_conversationHistory);
        
        // 3. ëŒ€ì•ˆ: JsonSchema ì—†ì´ ì¼ë°˜ì ì¸ ChatRequest ì‚¬ìš©
        var chatRequest = new ChatRequest(messages, Model.GPT4o);
        
        // 4. ë‹µë³€ ë°›ê¸° (ì¼ë°˜ì ì¸ ë°©ì‹)
        var response = await _openAIClient.ChatEndpoint.GetCompletionAsync(chatRequest);
        
        // 5. ë‹µë³€ ì„ íƒ ë° JSON íŒŒì‹±
        var choice = response.FirstChoice;
        // AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        var aiMessage = new Message(Role.Assistant, choice.Message.Content.ToString());
        _conversationHistory.Add(aiMessage);
        
        // JSON ë¬¸ìì—´ì„ NPCResponse ê°ì²´ë¡œ íŒŒì‹±
        NPCResponse npcResponse = null;
        string responseContent = choice.Message.Content.ToString();
        
        try
        {
            // ì‘ë‹µ ë‚´ìš©ì´ JSONì¸ì§€ í™•ì¸
            if (responseContent.Trim().StartsWith("{") && responseContent.Trim().EndsWith("}"))
            {
                npcResponse = JsonConvert.DeserializeObject<NPCResponse>(responseContent);
                Debug.Log($"âœ… JSON íŒŒì‹± ì„±ê³µ: {responseContent}");
            }
            else
            {
                Debug.LogWarning($"âš ï¸ JSON í˜•ì‹ì´ ì•„ë‹Œ ì‘ë‹µ: {responseContent}");
                throw new Exception("ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.");
            }
        }
        catch (Exception e)
        {
            Debug.LogError($"JSON íŒŒì‹± ì˜¤ë¥˜: {e.Message}");
            Debug.LogError($"ì›ë³¸ ì‘ë‹µ: {responseContent}");
            
            // íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
            npcResponse = new NPCResponse
            {
                ReplyMessage = responseContent.Contains("ëƒ¥") ? responseContent : responseContent + " ëƒ¥~",
                Appearance = "cute cat girl with fluffy ears",
                Emotion = "curious",
                StoryImageDescription = "cute anime cat girl character with fluffy ears, curious expression"
            };
        }
        
        
        // UI ì—…ë°ì´íŠ¸
        ResultTextUI.text = npcResponse.ReplyMessage;
        PlayTTS(npcResponse.ReplyMessage);
        GenerateImageFromNPCResponse(npcResponse);

    }
    private async void PlayTTS(string text)
    {
        var request = new SpeechRequest(text);
        var speechClip = await _openAIClient.AudioEndpoint.GetSpeechAsync(request);
        MyAudioSource.PlayOneShot(speechClip);
    }

    private async void GenerateImageFromNPCResponse(NPCResponse npcResponse)
    {
        try
        {
            // NPC ì‘ë‹µì—ì„œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± ìš”ì†Œ ì¶”ì¶œ
            string appearance = npcResponse.Appearance ?? "cute cat girl";
            string emotion = npcResponse.Emotion ?? "happy";
            string storyDescription = npcResponse.StoryImageDescription ?? "";
            
            // ì´ë¯¸ì§€ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ì¡°í•©
            string imagePrompt = "";
            
            // ì™¸ëª¨ ì •ë³´ ì¶”ê°€
            if (!string.IsNullOrEmpty(appearance))
            {
                imagePrompt += appearance + ", ";
            }
            
            // ê°ì • ì •ë³´ ì¶”ê°€
            if (!string.IsNullOrEmpty(emotion))
            {
                imagePrompt += emotion + " expression, ";
            }
            
            // ì „ì²´ ì´ë¯¸ì§€ ì„¤ëª… ì¶”ê°€
            if (!string.IsNullOrEmpty(storyDescription))
            {
                imagePrompt += storyDescription;
            }
            
            // ë¹ˆ í”„ë¡¬í”„íŠ¸ ë°©ì§€
            if (string.IsNullOrEmpty(imagePrompt.Trim()))
            {
                imagePrompt = "cute cat girl, happy";
            }
            
            // í”„ë¡¬í”„íŠ¸ ì €ì¥ ë° ë¡œê·¸
            _positivePrompt = imagePrompt.Trim().TrimEnd(',');
            Debug.Log($"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸: {_positivePrompt}");
            
            // ì´ë¯¸ì§€ ìƒì„± ì‹œì‘
            StartCoroutine(Client.GenerateImageAndWait(_positivePrompt, (imagePath) =>
            {
                if (!string.IsNullOrEmpty(imagePath))
                {
                    Debug.Log($"âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {imagePath}");
                    StartCoroutine(LoadAndShowImageAlternative(imagePath));
                }
                else
                {
                    Debug.LogError("âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨");
                }
            }));
        }
        catch (Exception e)
        {
            Debug.LogError($"âŒ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e.Message}");
        }
    }
    public IEnumerator LoadAndShowImageAlternative(string imagePath)
    {
        if (File.Exists(imagePath))
        {
            byte[] fileData = File.ReadAllBytes(imagePath);
            Texture2D tex = new Texture2D(2, 2);
            tex.LoadImage(fileData);
            image.texture = tex;
        }
        else
        {
            Debug.LogError("File not found: " + imagePath);
        }
    
        yield return null;
    }
}
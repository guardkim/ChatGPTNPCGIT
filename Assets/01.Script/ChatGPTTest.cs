using System;
using System.Collections;
using System.Collections.Generic;
using System.IO;
using OpenAI;
using OpenAI.Audio;
using OpenAI.Chat;
using OpenAI.Models;
using TMPro;
using UnityEngine;
using UnityEngine.Networking;
using UnityEngine.UI;
using Newtonsoft.Json;

public class ChatGPTTest : MonoBehaviour
{
    public TextMeshProUGUI ResultTextUI;
    public TMP_InputField PromptField;
    public Button SendButton;
    public RawImage image;
    public AudioSource MyAudioSource;
    public NPCSetting Settings;
    private string _sendingMessage;
    private OpenAIClient _openAIClient;

    public ComfyUIClient Client;
    // ëŒ€í™” ê¸°ë¡ì„ Message íƒ€ì…ìœ¼ë¡œ ì €ì¥
    private List<Message> _conversationHistory = new List<Message>();

    private string _positivePrompt = "";
    
    private void Start()
    {
        // API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” : 1. ChatGPT ì ‘ì†
        _openAIClient = new OpenAIClient(APIKeys.OPENAI_API_KEY);

        CreateImage();
        // CHAT-F
        // C  : Context         : ë¬¸ë§¥, ìƒí™©ì„ ë§ì´ ì•Œë ¤ì¤˜ë¼
        // H  : Hint            : ì˜ˆì‹œ ë‹µë³€ì„ ë§ì´ ì¤˜ë¼
        // A  : As A role       : ì—­í• ì„ ì œê³µí•´ë¼
        // T  : Target          : ë‹µë³€ì˜ íƒ€ê²Ÿì„ ì•Œë ¤ì¤˜ë¼
        // F  : Format          : ë‹µë³€ í˜•íƒœë¥¼ ì§€ì •í•´ë¼
        string systemMessage = Settings.Description;
        _conversationHistory.Add(new Message(Role.System, systemMessage));
    }
    public async void OnClickSendButton()
    {
        if (string.IsNullOrEmpty(PromptField.text)) return;
        if (_openAIClient == null) return;
        SendMessage(PromptField.text);
    }

    public void OnClickCreateImage()
    {
        CreateImage();
    }
    public void CreateImage()
    {
        StartCoroutine(Client.GenerateImageAndWait(_positivePrompt, (imagePath) =>
        {
            if (!string.IsNullOrEmpty(imagePath))
            {
                Debug.Log("Generated image path: " + imagePath);
                StartCoroutine(LoadAndShowImageAlternative(imagePath));
            }
            else
            {
                Debug.LogError("Failed to get image path");
            }
        }));
    }
    public async void SendMessage(string message)
    {
        PromptField.text = string.Empty;
        
        // ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        var userMessage = new Message(Role.User, message);
        _conversationHistory.Add(userMessage);
        
        // 2. ì „ì²´ ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        var messages = new List<Message>(_conversationHistory);
        
        // 3. ëŒ€ì•ˆ: JsonSchema ì—†ì´ ì¼ë°˜ì ì¸ ChatRequest ì‚¬ìš©
        var chatRequest = new ChatRequest(messages, Model.GPT4o);
        
        // 4. ë‹µë³€ ë°›ê¸° (ì¼ë°˜ì ì¸ ë°©ì‹)
        var response = await _openAIClient.ChatEndpoint.GetCompletionAsync(chatRequest);
        
        // 5. ë‹µë³€ ì„ íƒ ë° JSON íŒŒì‹±
        var choice = response.FirstChoice;
        // AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        var aiMessage = new Message(Role.Assistant, choice.Message.Content.ToString());
        _conversationHistory.Add(aiMessage);
        
        // JSON ë¬¸ìì—´ì„ NPCResponse ê°ì²´ë¡œ íŒŒì‹±
        NPCResponse npcResponse = null;
        string responseContent = choice.Message.Content.ToString();
        
        try
        {
            // ì‘ë‹µ ë‚´ìš©ì´ JSONì¸ì§€ í™•ì¸
            if (responseContent.Trim().StartsWith("{") && responseContent.Trim().EndsWith("}"))
            {
                npcResponse = JsonConvert.DeserializeObject<NPCResponse>(responseContent);
                Debug.Log($"âœ… JSON íŒŒì‹± ì„±ê³µ: {responseContent}");
            }
            else
            {
                Debug.LogWarning($"âš ï¸ JSON í˜•ì‹ì´ ì•„ë‹Œ ì‘ë‹µ: {responseContent}");
                throw new Exception("ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.");
            }
        }
        catch (Exception e)
        {
            Debug.LogError($"JSON íŒŒì‹± ì˜¤ë¥˜: {e.Message}");
            Debug.LogError($"ì›ë³¸ ì‘ë‹µ: {responseContent}");
            
            // íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
            npcResponse = new NPCResponse
            {
                ReplyMessage = responseContent,
                Appearance = "cute cat girl with fluffy ears",
                Emotion = "curious",
                StoryImageDescription = "cute anime cat girl character with fluffy ears, curious expression"
            };
        }
        
        
        // UI ì—…ë°ì´íŠ¸
        ResultTextUI.text = npcResponse.ReplyMessage;
        PlayTTS(npcResponse.ReplyMessage);
        GenerateImageFromNPCResponse(npcResponse);

    }
    private async void PlayTTS(string text)
    {
        var request = new SpeechRequest(text);
        var speechClip = await _openAIClient.AudioEndpoint.GetSpeechAsync(request);
        MyAudioSource.PlayOneShot(speechClip);
    }

    private async void GenerateImageFromNPCResponse(NPCResponse npcResponse)
    {
        try
        {
            // NPC ì‘ë‹µì—ì„œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± ìš”ì†Œ ì¶”ì¶œ
            string appearance = npcResponse.Appearance ?? "cute cat girl";
            string emotion = npcResponse.Emotion ?? "happy";
            string storyDescription = npcResponse.StoryImageDescription ?? "";
            
            // ì´ë¯¸ì§€ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ì¡°í•©
            string imagePrompt = "";
            
            // ì™¸ëª¨ ì •ë³´ ì¶”ê°€
            if (!string.IsNullOrEmpty(appearance))
            {
                imagePrompt += appearance + ", ";
            }
            
            // ê°ì • ì •ë³´ ì¶”ê°€
            if (!string.IsNullOrEmpty(emotion))
            {
                imagePrompt += emotion + " expression, ";
            }
            
            // ì „ì²´ ì´ë¯¸ì§€ ì„¤ëª… ì¶”ê°€
            if (!string.IsNullOrEmpty(storyDescription))
            {
                imagePrompt += storyDescription;
            }
            
            // ë¹ˆ í”„ë¡¬í”„íŠ¸ ë°©ì§€
            if (string.IsNullOrEmpty(imagePrompt.Trim()))
            {
                imagePrompt = "cute cat girl, happy";
            }
            
            // í”„ë¡¬í”„íŠ¸ ì €ì¥ ë° ë¡œê·¸
            _positivePrompt = imagePrompt.Trim().TrimEnd(',');
            Debug.Log($"ğŸ¨ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸: {_positivePrompt}");
            
            // ì´ë¯¸ì§€ ìƒì„± ì‹œì‘
            StartCoroutine(Client.GenerateImageAndWait(_positivePrompt, (imagePath) =>
            {
                if (!string.IsNullOrEmpty(imagePath))
                {
                    Debug.Log($"âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {imagePath}");
                    StartCoroutine(LoadAndShowImageAlternative(imagePath));
                }
                else
                {
                    Debug.LogError("âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨");
                }
            }));
        }
        catch (Exception e)
        {
            Debug.LogError($"âŒ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e.Message}");
        }
    }
    public IEnumerator LoadAndShowImageAlternative(string imagePath)
    {
        if (File.Exists(imagePath))
        {
            byte[] fileData = File.ReadAllBytes(imagePath);
            Texture2D tex = new Texture2D(2, 2);
            tex.LoadImage(fileData);
            image.texture = tex;
        }
        else
        {
            Debug.LogError("File not found: " + imagePath);
        }
    
        yield return null;
    }
}